{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "官网地址：https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
    "\n",
    "# Pytorch 是什么？\n",
    "它是一个基于python的科学计算库，致力于下面方面：\n",
    "1、在更强悍的GPU上面替代numpy\n",
    "2、一个深度学习的研究平台，提供最大的灵活性和速度\n",
    "\n",
    "## Tensors张量\n",
    "所谓tensor和numpy的ndarray非常相似，能用于在GPU上面加速运算。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import print_function  # 在开头加上from __future__ import print_function这句之后，即使在python2.X，使用print就得像python3.X那样加括号使用。python2.X中print不需要括号，而在python3.X中则需要。\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意\n",
    "一个违背初始化的矩阵是不被鼓励提倡的，但不包含用在使用它之前用已知的值定义的这种情况。\n",
    "当一个未初始化的矩阵被创建后，不论设置值被分配内存的时候，就是它被初始化值的时候。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建一个未初始化的5x3的矩阵\n",
    "x = torch.empty(5,3)\n",
    "print(x)  # 手册上写的out全部是0，我运行的并不是！不知道是不是我使用python3.6的缘故\n",
    "\n",
    "# 创建一个随机初始化的矩阵\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "\n",
    "# 创建一个dtype为long的5x3的全零矩阵\n",
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "# 从数据data直接创建tensor张量\n",
    "x = torch.tensor([5.5,3])\n",
    "print(x)\n",
    "\n",
    "\n",
    "# 基于已经存在的tensor来创建一个tensor。 除非用户提供了新值，否则这些方法将重用输入tensor的属性，例如dtype\n",
    "x = x.new_ones(5,3,dtype=torch.double)  # new_* 这类方法需要输入一个sizes，x是要已经有的！！结果size可以和原来不同\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)  # 覆盖dtype\n",
    "print(x)  # 结果是和原来的size相同\n",
    "\n",
    "\n",
    "# 获取tensor的size，用x.size()\n",
    "print(x.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意\n",
    "torch.Size事实上是一个tuple，因此它支持所有的tuple操作\n",
    "\n",
    "## 操作"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 加法的语法1\n",
    "y = torch.rand(5,3)\n",
    "print(x + y)\n",
    "\n",
    "# 加法的语法2\n",
    "print(torch.add(x,y))\n",
    "\n",
    "# 加法：提供一个输出的参数tensor来接收结果\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)\n",
    "\n",
    "# 加法：结果原地替换的方法 in-place，把x加到y上面，y的值也因此改变\n",
    "y.add_(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意\n",
    "任何的操作，只要它后面跟了个_，例如x.copy_(y)，x.t_()，都会改变x自身！"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对于所有的pytorch的tensor，你都可以使用标准的numpy-like（类似于numpy）的索引！ 分片\n",
    "print(x[:,1])\n",
    "\n",
    "# 改变tensor的形状，resizing，如果你想要resize或者说reshape一个tensor张量，你可以使用torch.view\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)  # 哪一维的size如果写了-1，那么它会自动计算，是参照着其他维的变化而变化的，不想计算的懒人写法\n",
    "print(x.size(),y.size(),z.size())\n",
    "\n",
    "# 如果你有一个只有一个元素的tensor，那么使用 .item() 方法得到它的值（它的值是一个python的数值）\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "扩充阅读\n",
    "有超过100的tensor的操作，包括变形，索引，截取，数学计算，线性代数，随机数值，等等\n",
    "https://pytorch.org/docs/torch\n",
    "\n",
    "numpy的桥梁作用\n",
    "可以将一个tensor转换成numpy的array，反之亦然。\n",
    "tensor和numpy的array将共享他们的下面的内存地址（在CPU上面运行的话），改变一个，另一个也随之改变"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 将tensor转换成numpy的array\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "\n",
    "# 我们来看看tensor改变，numpy的array的值是不是也变了\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "# 将numpy array转换成torch tensor\n",
    "# 见证一下改变np array的值，对应的tensor也自动改变\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# 除了字符类的tensor之外，在CPU上面所有的tensor都支持和numpy的相互转换"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CUDA tensor\n",
    "使用.to方法，可以将tensor移动到任何设备"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 只有到cuda有的时候，才能运行，我这穷屌的电脑，应该运行不了。\n",
    "# 我们使用\"torch.devie\"对象将tensor移进GPU，移出GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # 一个CUDA设备的对象\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上面创建一个tensor\n",
    "    x = x.to(device)  # 或者使用to方法，移动到GPU\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))  # to方法移动到CPU，to方法同时可以改变dtype！！！\n",
    "\n",
    "# 果然是没有GPU，没有CUDA！！\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}